*********************************************************************************************
Scenario #1:Load data into a Pig relation without a schema
launch pig.
grunt>movies = LOAD '/user/maria_dev/sqoop_movielens/movies' using PigStorage(',');

You are done, a relation movies has been created without a schema. To verify this -
grunt> describe movies;

And output is -
Schema for movies unknown.

Index or positional notation is used to access each column e.g. $0, $1 etc.
Let's see an example:

grunt>movies_id = FOREACH movies GENERATE (int)$0;

*********************************************************************************************
Scenario #2:Load data into a Pig relation with a schema

grunt>movies = LOAD '/user/maria_dev/sqoop_movielens/movies' using PigStorage(',')
AS (id: INT, title: CHARARRAY, release_date: DATE);

grunt> describe movies;
movies: {id: int,title: chararray,release_date: chararray}

grunt>movies_id = FOREACH movies GENERATE id;
grunt>DUMP movies_id;

*********************************************************************************************
Scenario #3:Load data from a Hive table into a Pig relation

Launch Pig with HCatalog as pig -useHCatalog
grunt>

Let's access Hive now..
grunt>dim_customer = LOAD 'dim_customer' USING org.apache.hive.hcatalog.pig.HCatloader();

Note - in the sandbox there was an error, check it later.
ls: cannot access /usr/hdp/2.6.3.0-235/hive/lib/slf4j-api-*.jar: No such file or directory
ls: cannot access /usr/hdp/2.6.3.0-235/hive-hcatalog/lib/*hbase-storage-handler-*.jar: 
No such file or directory

*********************************************************************************************
Scenario #4:Use Pig to transform data into a specified format

check this later..

*********************************************************************************************
Scenario #5:Transform data to match a given Hive schema

Just try to understand mapping between Hive's and Pig's datatypes. will put mapping below soon.

*********************************************************************************************
Scenario #6:Group the data of one or more Pig relations

grunt> a = LOAD '/apps/hive/warehouse/xademo.db/customer_details' USING PigStorage('|');

remove column headers from the input..
grunt> a_no_header = FILTER a BY $0 != 'PHONE_NUM';

grunt> a_group = GROUP a_no_header ALL;
grunt> a_total_count = FOREACH a_group GENERATE COUNT_STAR(a_no_header)as total_cnt;
grunt> DUMP a_total_count;
*********************************************************************************************
Scenario #7:Use Pig to remove records with null values from a relation

grunt> a = LOAD '/apps/hive/warehouse/xademo.db/customer_details' USING PigStorage('|');
grunt> a_no_header = FILTER a BY $0 != 'PHONE_NUM';
grunt> a_no_nulls = FILTER a_no_header BY ($5 IS NOT NULL);
grunt> a_group = GROUP a_no_nulls ALL;
grunt> a_count = FOREACH a_group GENERATE COUNT_STAR(a_no_nulls) as cnt;
grunt> DUMP a_count;
*********************************************************************************************
Scenario #8:Store the data from a Pig relation into a folder in HDFS

grunt> a = LOAD '/apps/hive/warehouse/xademo.db/customer_details' USING PigStorage('|');

Run below command to check if the directory where Pig Relation "a" will be stored..
grunt> fs -ls /user/root/customer;

The directory is missing..
ls: `/user/root/customer': No such file or directory

Following command will also create the directory..
grunt> STORE a INTO '/user/root/customer';

Now check the directory again..
grunt> fs -ls /user/root/customer;

Let's check what is inside the file..
grunt> fs -cat /user/root/customer/part*;

Let's delete the directory..
grunt> fs -rm -R /user/root/customer;

Let's load the file again but with some variation..
grunt> STORE a INTO '/user/root/customer' USING PigStorage('*');

Let's check what is inside the file again..
grunt> fs -cat /user/root/customer/part*;

You can also store file as BinStorage. Explore this later.

*********************************************************************************************
Scenario #9:
a) Within a Pig script, register a JAR file of User Defined Functions
b) Within a Pig script, define an alias for a User Defined Function
c) Within a Pig script, invoke a User Defined Function

Let's find some *.jar files.
	$ sudo find / -name "*piggybank*.jar"

	/usr/hdp/2.6.3.0-235/pig/piggybank.jar
	/usr/hdp/2.6.3.0-235/pig/lib/piggybank.jar
	/hadoop/yarn/local/filecache/14/pig.tar.gz/pig/lib/piggybank.jar
	/hadoop/yarn/local/filecache/14/pig.tar.gz/pig/contrib/piggybank/java/piggybank.jar

Let's register the jar file located @ /usr/hdp/2.6.3.0-235/pig/piggybank.jar

First launch pig and then register at Grunt:
	grunt> REGISTER /usr/hdp/2.6.3.0-235/pig/piggybank.jar

Let's sneek peak inside this jar file first by quitting Grunt and checking the content:
	$ jar tvf /usr/hdp/2.6.3.0-235/pig/piggybank.jar

so we saw there is a UPPER class to covert a character to upper case in the jar file.
Let's make an alias UPPER_CASE using below command:
	grunt> DEFINE UPPER_CASE org.apache.pig.piggybank.evaluation.string.UPPER;

The fully qualified path of UPPER is found from the jar file as below -
	org/apache/pig/piggybank/evaluation/string/UPPER.class
Note: we need to omit "/" and instead use ".", also omit the suffix ".class".

Now let's use this alias in pig transformation:
	
	grunt> x = LOAD '/user/maria_dev/sqoop_movielens/movies' using PigStorage(',');
	grunt> x_limit = LIMIT a 10;
	grunt> y = FOREACH x_limit GENERATE $1 AS  normal_case, UPPER_CASE($1) AS upper_case;
	grunt> DUMP y;

Now you will see that first column is in lower case but the second column is in the upper case.

Here we have implemented all the 3 scenarios!
*********************************************************************************************